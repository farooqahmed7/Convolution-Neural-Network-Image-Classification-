{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network.\n",
    "\n",
    "## Image Recognition (Binary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "pd.options.display.max_columns=30\n",
    "pd.options.display.max_rows=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import keras as ks\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# This is helpful for preprocessing of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check version of tensorflow.\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Data Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying different \"Transformations\" or combinations for images to avoid 'Overfitting'. We us geometrical transformations or some zooms or some rotations on our images like 'Image Augmentation'.\n",
    "# Image Augmentation helps in transforming the images of our training to avoid overfitting.\n",
    "# It creates an object/instance as 'train_datagen' of \"Image Data Generator\" class which represents the tool which applies all the transformations on the images of the training set. \n",
    "# It's capturing 'INVARIANCE' by creating more images.\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "# Rescale: This is feature scaling of our each and every single one of our pixels by dividing thier value with 255.Because each pixel takes a value in between 0 & 255.\n",
    "# With this we get all the pixel values in between 0 & 1 as Normalization. Feature Scaling is very important for 'Neural Networks'.\n",
    "# Zoom range: Zooming in or zooming out on the images.\n",
    "# Horizontal flip: It consists of flipping of images horizontally.\n",
    "# Shear range: Its type of transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Importing training set by accessing it from directory and at the same time creating these batches and resizing the images, to reduce the computations of the machines i.e to make it less  compute intensive.\n",
    "# Flow_From_Directory: To access the training set from our directory.\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('training_set', target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Target_size: Final size of the images when we feed into the CNN. If we increase this the training time also increases.\n",
    "# Batch size: Number of images we need in each batch. Default is 32.\n",
    "# Class_mode: This specifies whether the target is binary('cat' or 'dog') or non-binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "# Here in 'ImageDataGenerator' we are not adding any arguments or transformations since its the test data. Therefore we just rescale it and keep it in original state.\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set', target_size=(64,64), batch_size=32, class_mode='binary') # Same as training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part-2 Building the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN by creating a variable using Sequential class.\n",
    "\n",
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-1 Convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Convolution with add method.\n",
    "# Adding feature detector or kernal or filter to the convolution.\n",
    "# Convolution Layer is an object of 'Conv2D' class, an dense class which allows to bulid the fully connected layer.\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3])) \n",
    "\n",
    "# Filters(kernals): Number of feature detectors required to apply for our images.\n",
    "# Kernal_size: This is the size of that feature detector i.e the number of rows and number of columns.\n",
    "# Input shape: Since we are using color images i.e RGB color and we reshaped it into 64,64;therefore we have to use [64,64,3]. 3 is used for RGB and 1 is used for Black & white.\n",
    "# Input_shape is only given for the first layer of CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-2 Pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max_Pooling layer to our CNN.\n",
    "# using MaxPool2D class.\n",
    "# Pool_size: 2 is used i.e 2X2 Matrix.\n",
    "# Strides: Sliding 2X2 pixels i.e to what number of pixels is the frame is shifted.\n",
    "# Padding: With padding =valid; we just ignore last 2 cells of empty matrix during strides.With Padding it does'nt give much effect on the model. \n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding 2nd Convolution Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "# Remove 'input_shape' because we are adding 2nd Conv Layer. \n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-3 Flattening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result of convolution and pooling is flattened.\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-4 Full Connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu',))\n",
    "\n",
    "# Units: No of Hidden Neurons in the fully connected layer.\n",
    "# We took large number of neurons since its complex problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-5 Output Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Units will be 1 i.e Binary classification Prediction\n",
    "# Activation function will be 'sigmoid' for output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part-3 Training the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile is the method which takes as inputs.\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# In complier we have to enter 3 parameters i.e 1.Optimizer,  2.Loss Function and 3.Metrics. \n",
    "\n",
    "# Adam Optimizer: To get Stochastic Optimizer, Optimizer updates the weights through 'Stochastic Gradient Descent'.\n",
    "# Loss function: For Binary classification it should be 'binary_ crossentropy' and for non-binary it should be 'categorical_crossentropy'\n",
    "# Metrics: 'Accuracy' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the CNN on the 'train_set' and evaluating it on the 'test_set'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.6523 - acc: 0.6098Epoch 1/25\n",
      "250/250 [==============================] - 203s 814ms/step - loss: 0.6520 - acc: 0.6101 - val_loss: 0.6163 - val_acc: 0.6490\n",
      "Epoch 2/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.6831Epoch 1/25\n",
      "250/250 [==============================] - 105s 420ms/step - loss: 0.5900 - acc: 0.6831 - val_loss: 0.5675 - val_acc: 0.7100\n",
      "Epoch 3/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.5537 - acc: 0.7080Epoch 1/25\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.5534 - acc: 0.7084 - val_loss: 0.5343 - val_acc: 0.7360\n",
      "Epoch 4/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.7322Epoch 1/25\n",
      "250/250 [==============================] - 106s 425ms/step - loss: 0.5225 - acc: 0.7321 - val_loss: 0.5287 - val_acc: 0.7430\n",
      "Epoch 5/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4930 - acc: 0.7578Epoch 1/25\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 0.4930 - acc: 0.7577 - val_loss: 0.5017 - val_acc: 0.7535\n",
      "Epoch 6/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4673 - acc: 0.7787Epoch 1/25\n",
      "250/250 [==============================] - 105s 419ms/step - loss: 0.4677 - acc: 0.7781 - val_loss: 0.4706 - val_acc: 0.7765\n",
      "Epoch 7/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4552 - acc: 0.7804Epoch 1/25\n",
      "250/250 [==============================] - 105s 420ms/step - loss: 0.4549 - acc: 0.7803 - val_loss: 0.4523 - val_acc: 0.7900\n",
      "Epoch 8/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4342 - acc: 0.7956Epoch 1/25\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.4345 - acc: 0.7955 - val_loss: 0.4607 - val_acc: 0.7800\n",
      "Epoch 9/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4165 - acc: 0.8080Epoch 1/25\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 0.4165 - acc: 0.8084 - val_loss: 0.4566 - val_acc: 0.7930\n",
      "Epoch 10/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8112Epoch 1/25\n",
      "250/250 [==============================] - 107s 429ms/step - loss: 0.4071 - acc: 0.8111 - val_loss: 0.4814 - val_acc: 0.7795\n",
      "Epoch 11/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8199Epoch 1/25\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.3949 - acc: 0.8199 - val_loss: 0.4457 - val_acc: 0.7945\n",
      "Epoch 12/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8296Epoch 1/25\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 0.3774 - acc: 0.8294 - val_loss: 0.4439 - val_acc: 0.8020\n",
      "Epoch 13/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8436Epoch 1/25\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 0.3569 - acc: 0.8436 - val_loss: 0.4386 - val_acc: 0.8010\n",
      "Epoch 14/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8459Epoch 1/25\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 0.3468 - acc: 0.8456 - val_loss: 0.4272 - val_acc: 0.8190\n",
      "Epoch 15/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3357 - acc: 0.8519Epoch 1/25\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 0.3362 - acc: 0.8515 - val_loss: 0.4683 - val_acc: 0.7880\n",
      "Epoch 16/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8614Epoch 1/25\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.3179 - acc: 0.8616 - val_loss: 0.4809 - val_acc: 0.8015\n",
      "Epoch 17/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3140 - acc: 0.8632Epoch 1/25\n",
      "250/250 [==============================] - 106s 423ms/step - loss: 0.3139 - acc: 0.8634 - val_loss: 0.4696 - val_acc: 0.7995\n",
      "Epoch 18/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2903 - acc: 0.8753Epoch 1/25\n",
      "250/250 [==============================] - 106s 425ms/step - loss: 0.2899 - acc: 0.8756 - val_loss: 0.4524 - val_acc: 0.8065\n",
      "Epoch 19/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.8822Epoch 1/25\n",
      "250/250 [==============================] - 105s 419ms/step - loss: 0.2745 - acc: 0.8820 - val_loss: 0.4919 - val_acc: 0.8080\n",
      "Epoch 20/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.8868Epoch 1/25\n",
      "250/250 [==============================] - 109s 436ms/step - loss: 0.2691 - acc: 0.8865 - val_loss: 0.4747 - val_acc: 0.8080\n",
      "Epoch 21/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.8889Epoch 1/25\n",
      "250/250 [==============================] - 108s 432ms/step - loss: 0.2642 - acc: 0.8891 - val_loss: 0.4608 - val_acc: 0.8045\n",
      "Epoch 22/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9000Epoch 1/25\n",
      "250/250 [==============================] - 109s 435ms/step - loss: 0.2403 - acc: 0.9001 - val_loss: 0.5244 - val_acc: 0.7910\n",
      "Epoch 23/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9061Epoch 1/25\n",
      "250/250 [==============================] - 106s 423ms/step - loss: 0.2298 - acc: 0.9059 - val_loss: 0.5009 - val_acc: 0.8125\n",
      "Epoch 24/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9090Epoch 1/25\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.2154 - acc: 0.9089 - val_loss: 0.6221 - val_acc: 0.7720\n",
      "Epoch 25/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9169Epoch 1/25\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 0.2024 - acc: 0.9166 - val_loss: 0.5709 - val_acc: 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b2772bf5f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In fit method we  give different parameters i.e train_set and test_set for validating and epochs.\n",
    "cnn.fit(x=train_set, validation_data=test_set, epochs= 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-4 Making a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1B277BFAEF0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploying our CNN on each of these single images & Deploying CNN in Production on a single observation.\n",
    "\n",
    "from keras.preprocessing import image \n",
    "\n",
    "# To load image as a variable.\n",
    "\n",
    "test_image= image.load_img('cat_or_dog_1.jpg', target_size=(64,64))\n",
    "# target_size should be same as used in training_set.\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 54.,  58.,   7.],\n",
       "        [ 58.,  63.,   9.],\n",
       "        [ 64.,  67.,  10.],\n",
       "        ...,\n",
       "        [136., 144.,  71.],\n",
       "        [140., 150.,  77.],\n",
       "        [139., 149.,  78.]],\n",
       "\n",
       "       [[ 48.,  54.,   6.],\n",
       "        [ 51.,  58.,   7.],\n",
       "        [ 58.,  63.,   9.],\n",
       "        ...,\n",
       "        [129., 137.,  64.],\n",
       "        [139., 149.,  78.],\n",
       "        [141., 151.,  80.]],\n",
       "\n",
       "       [[ 48.,  56.,   7.],\n",
       "        [ 48.,  56.,   7.],\n",
       "        [ 54.,  61.,  10.],\n",
       "        ...,\n",
       "        [123., 130.,  63.],\n",
       "        [136., 145.,  80.],\n",
       "        [140., 149.,  82.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 46.,  55.,  12.],\n",
       "        [ 42.,  50.,   9.],\n",
       "        [ 38.,  49.,   9.],\n",
       "        ...,\n",
       "        [239., 205., 170.],\n",
       "        [235., 209., 186.],\n",
       "        [229., 202., 173.]],\n",
       "\n",
       "       [[ 50.,  57.,  15.],\n",
       "        [ 42.,  50.,   9.],\n",
       "        [ 44.,  52.,  11.],\n",
       "        ...,\n",
       "        [234., 200., 162.],\n",
       "        [236., 206., 178.],\n",
       "        [234., 203., 174.]],\n",
       "\n",
       "       [[ 53.,  59.,  13.],\n",
       "        [ 43.,  51.,  10.],\n",
       "        [ 49.,  56.,  12.],\n",
       "        ...,\n",
       "        [231., 195., 159.],\n",
       "        [235., 213., 190.],\n",
       "        [233., 206., 179.]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting PIL image format into an 2-d array.Because predict method uses input as an array.\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 54.,  58.,   7.],\n",
       "         [ 58.,  63.,   9.],\n",
       "         [ 64.,  67.,  10.],\n",
       "         ...,\n",
       "         [136., 144.,  71.],\n",
       "         [140., 150.,  77.],\n",
       "         [139., 149.,  78.]],\n",
       "\n",
       "        [[ 48.,  54.,   6.],\n",
       "         [ 51.,  58.,   7.],\n",
       "         [ 58.,  63.,   9.],\n",
       "         ...,\n",
       "         [129., 137.,  64.],\n",
       "         [139., 149.,  78.],\n",
       "         [141., 151.,  80.]],\n",
       "\n",
       "        [[ 48.,  56.,   7.],\n",
       "         [ 48.,  56.,   7.],\n",
       "         [ 54.,  61.,  10.],\n",
       "         ...,\n",
       "         [123., 130.,  63.],\n",
       "         [136., 145.,  80.],\n",
       "         [140., 149.,  82.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 46.,  55.,  12.],\n",
       "         [ 42.,  50.,   9.],\n",
       "         [ 38.,  49.,   9.],\n",
       "         ...,\n",
       "         [239., 205., 170.],\n",
       "         [235., 209., 186.],\n",
       "         [229., 202., 173.]],\n",
       "\n",
       "        [[ 50.,  57.,  15.],\n",
       "         [ 42.,  50.,   9.],\n",
       "         [ 44.,  52.,  11.],\n",
       "         ...,\n",
       "         [234., 200., 162.],\n",
       "         [236., 206., 178.],\n",
       "         [234., 203., 174.]],\n",
       "\n",
       "        [[ 53.,  59.,  13.],\n",
       "         [ 43.,  51.,  10.],\n",
       "         [ 49.,  56.,  12.],\n",
       "         ...,\n",
       "         [231., 195., 159.],\n",
       "         [235., 213., 190.],\n",
       "         [233., 206., 179.]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding extra dimension.\n",
    "# Since our images are trained in batches of images. Hence we need to add an extra dimension using numpy array.\n",
    "test_image=np.expand_dims(test_image, axis=0)\n",
    "# axis=0(where we are adding), Because we are adding our dimension of the batch adding to our image will be first dimension.\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOG\n"
     ]
    }
   ],
   "source": [
    "result= cnn.predict(test_image)\n",
    "# This predict gives 0 or 1 as output, but we need in form of 'Cat' or 'Dog'\n",
    "\n",
    "train_set.class_indices\n",
    "# Using class_indices attribute, it figures out to classify what is 0 and what is 1 respectively.  \n",
    "\n",
    "# 1 is Dog and 0 is Cat\n",
    "if result[0][0] ==1:#[0] is batch and [0] is first element of the batch \n",
    "    prediction='DOG'\n",
    "else:\n",
    "    prediction='CAT'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOG\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing External Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1B2772BF128>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image \n",
    "\n",
    "test_image= image.load_img('cat.4014.jpg', target_size=(64,64))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT\n"
     ]
    }
   ],
   "source": [
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "# Adding extra dimension.\n",
    "test_image=np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result= cnn.predict(test_image)\n",
    "\n",
    "train_set.class_indices\n",
    "\n",
    "# 1 is Dog and 0 is Cat\n",
    "if result[0][0] ==1:\n",
    "    prediction='DOG'\n",
    "else:\n",
    "    prediction='CAT'\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
